# -*- coding: utf-8 -*-
"""PBL4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fNAOkpAxPp0YLavGX8Nu1WFljjbwp8W8

**Actividad PBL 4: Arboles de decisión**

Autores:


*   Daniel Makoszay Castañón       - A01750046
*   Santiago Jiménez Pasillas      - A01749907
*   Santiago Palavicini Saldívar   - A01749103
*   Ximena Serna Mendoza           - A01749870
*   Guillermo Ian Barbosa Martínez - A01747926

# **Modelo hecho por el equipo**
"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score, mean_squared_error
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import export_graphviz
from six import StringIO
import pydotplus
from IPython.display import Image
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

titanic = pd.read_csv('/content/titanic.csv')
titanic.head()

titanic = titanic.drop(['PassengerId','Name', 'Ticket', 'Cabin'], axis=1)
titanic.head()

le = LabelEncoder()
titanic['Sex'] = le.fit_transform(titanic['Sex'])
titanic['Embarked'] = le.fit_transform(titanic['Embarked'])
titanic.head()

titanic.info()

titanic = titanic.dropna()

feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp','Parch','Fare','Embarked']
X = titanic.drop('Survived', axis=1)
y = titanic['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

dec_tree = DecisionTreeClassifier(criterion="entropy", max_depth=4)
dec_tree.fit(X_train, y_train)

#   Predicción con datos de entrenamiento
dec_pred_train = dec_tree.predict(X_train)

print("Basic Decision Tree (Entrenamiento):\n")
print(f"Accuracy           : {accuracy_score(y_train, dec_pred_train):.4f}")
print(f"Precision          : {precision_score(y_train, dec_pred_train):.4f}")
print(f"Recall             : {recall_score(y_train, dec_pred_train):.4f}")
print(f"F1-score           : {f1_score(y_train, dec_pred_train):.4f}")
print(f"Log loss           : {log_loss(y_train, dec_pred_train):.4f}")
print(f"AUC-ROC            : {roc_auc_score(y_train, dec_pred_train):.4f}")
print(f"Mean squared error : {mean_squared_error(y_train, dec_pred_train):.4f}\n")
print(classification_report(y_train, dec_pred_train), '\n')

conf_matrix = confusion_matrix(y_train, dec_pred_train)                   # Hacemos la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Matriz de Confusión del Entrenamiento del Árbol de Decisión Básico")
plt.xlabel("Predicciones")
plt.ylabel("Reales")
plt.show()

#   Predicción con datos de prueba
dec_pred_test = dec_tree.predict(X_test)

print("Basic Decision Tree (Entrenamiento):\n")
print(f"Accuracy           : {accuracy_score(y_test, dec_pred_test):.4f}")
print(f"Precision          : {precision_score(y_test, dec_pred_test):.4f}")
print(f"Recall             : {recall_score(y_test, dec_pred_test):.4f}")
print(f"F1-score           : {f1_score(y_test, dec_pred_test):.4f}")
print(f"Log loss           : {log_loss(y_test, dec_pred_test):.4f}")
print(f"AUC-ROC            : {roc_auc_score(y_test, dec_pred_test):.4f}")
print(f"Mean squared error : {mean_squared_error(y_test, dec_pred_test):.4f}\n")
print(classification_report(y_test, dec_pred_test), '\n')

conf_matrix = confusion_matrix(y_test, dec_pred_test)                   # Hacemos la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Matriz de Confusión de la Validación del Árbol de Decisión Básico")
plt.xlabel("Predicciones")
plt.ylabel("Reales")
plt.show()

dot_data = StringIO()
export_graphviz(dec_tree, out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_cols,class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('basic_decision_tree.png')
Image(graph.create_png())

"""# **Modelos hechos por Watson**

## **Random Forest**
"""

from sklearn.ensemble import RandomForestClassifier

# Create a Random Forest model
rf_model = RandomForestClassifier()

# Train the model on the training data
rf_model.fit(X_train, y_train)

# Make predictions on the training data
rf_pred_train = rf_model.predict(X_train)

print("Random Forest (Entrenamiento):\n")
print(f"Accuracy           : {accuracy_score(y_train, rf_pred_train):.4f}")
print(f"Precision          : {precision_score(y_train, rf_pred_train):.4f}")
print(f"Recall             : {recall_score(y_train, rf_pred_train):.4f}")
print(f"F1-score           : {f1_score(y_train, rf_pred_train):.4f}")
print(f"Log loss           : {log_loss(y_train, rf_pred_train):.4f}")
print(f"AUC-ROC            : {roc_auc_score(y_train, rf_pred_train):.4f}")
print(f"Mean squared error : {mean_squared_error(y_train, rf_pred_train):.4f}\n")
print(classification_report(y_train, rf_pred_train), '\n')

conf_matrix = confusion_matrix(y_train, rf_pred_train)                   # Hacemos la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Matriz de Confusión del Entrenamiento del Random Forest")
plt.xlabel("Predicciones")
plt.ylabel("Reales")
plt.show()

# Make predictions on the testing data
rf_pred_test = rf_model.predict(X_test)

print("Random Forest (Prueba):\n")
print(f"Accuracy           : {accuracy_score(y_test, rf_pred_test):.4f}")
print(f"Precision          : {precision_score(y_test, rf_pred_test):.4f}")
print(f"Recall             : {recall_score(y_test, rf_pred_test):.4f}")
print(f"F1-score           : {f1_score(y_test, rf_pred_test):.4f}")
print(f"Log loss           : {log_loss(y_test, rf_pred_test):.4f}")
print(f"AUC-ROC            : {roc_auc_score(y_test, rf_pred_test):.4f}")
print(f"Mean squared error : {mean_squared_error(y_test, rf_pred_test):.4f}\n")
print(classification_report(y_test, rf_pred_test), '\n')

conf_matrix = confusion_matrix(y_test, rf_pred_test)                   # Hacemos la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Matriz de Confusión de la Validación del Random Forest")
plt.xlabel("Predicciones")
plt.ylabel("Reales")
plt.show()

dot_data = StringIO()
export_graphviz(rf_model.estimators_[0], out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True, feature_names = feature_cols, class_names=['0','1'])

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('random_forest.png')
Image(graph.create_png())

"""## **Gradient Boosting**"""

import numpy as np
from sklearn.ensemble import GradientBoostingClassifier

# Create a Gradient Boosting model
gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42, learning_rate=0.1)

# Train the model on the training data
gb_model.fit(X_train, y_train)

# Make predictions on the training data
gb_pred_train = gb_model.predict(X_train)

print("Gradient Boosting (Entrenamiento):\n")
print(f"Accuracy           : {accuracy_score(y_train, gb_pred_train):.4f}")
print(f"Precision          : {precision_score(y_train, gb_pred_train):.4f}")
print(f"Recall             : {recall_score(y_train, gb_pred_train):.4f}")
print(f"F1-score           : {f1_score(y_train, gb_pred_train):.4f}")
print(f"Log loss           : {log_loss(y_train, gb_pred_train):.4f}")
print(f"AUC-ROC            : {roc_auc_score(y_train, gb_pred_train):.4f}")
print(f"Mean squared error : {mean_squared_error(y_train, gb_pred_train):.4f}\n")
print(classification_report(y_train, gb_pred_train), '\n')

conf_matrix = confusion_matrix(y_train, gb_pred_train)                   # Hacemos la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Matriz de Confusión del Entrenamiento del Modelo Gradient Boosting")
plt.xlabel("Predicciones")
plt.ylabel("Reales")
plt.show()

# Make predictions on the testing data
gb_pred_test = gb_model.predict(X_test)

print("Gradient Boosting (Prueba):\n")
print(f"Accuracy           : {accuracy_score(y_test, gb_pred_test):.4f}")
print(f"Precision          : {precision_score(y_test, gb_pred_test):.4f}")
print(f"Recall             : {recall_score(y_test, gb_pred_test):.4f}")
print(f"F1-score           : {f1_score(y_test, gb_pred_test):.4f}")
print(f"Log loss           : {log_loss(y_test, gb_pred_test):.4f}")
print(f"AUC-ROC            : {roc_auc_score(y_test, gb_pred_test):.4f}")
print(f"Mean squared error : {mean_squared_error(y_test, gb_pred_test):.4f}\n")
print(classification_report(y_test, gb_pred_test), '\n')

conf_matrix = confusion_matrix(y_test, gb_pred_test)                   # Hacemos la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Matriz de Confusión de la Validación del Modelo Gradient Boosting")
plt.xlabel("Predicciones")
plt.ylabel("Reales")
plt.show()

# Graficación de un árbol aleatorio
import random
random_tree = gb_model.estimators_[random.randint(0, len(gb_model.estimators_) - 1), 0]

dot_data = StringIO()
export_graphviz(
    random_tree,
    out_file=dot_data, filled=True, rounded=True,
    special_characters=True,
    feature_names = feature_cols, class_names=['0','1']
)

graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('gradient_boosting.png')
Image(graph.create_png())

"""## **XGBoost**"""

import xgboost as xgb

# Create an XGBoost model
xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42)

# Train the model on the training data
xgb_model.fit(X_train, y_train)

# Make predictions on the training data
xgb_pred_train = xgb_model.predict(X_train)

print("XG Boost (Entrenamiento):\n")
print(f"Accuracy           : {accuracy_score(y_train, xgb_pred_train):.4f}")
print(f"Precision          : {precision_score(y_train, xgb_pred_train):.4f}")
print(f"Recall             : {recall_score(y_train, xgb_pred_train):.4f}")
print(f"F1-score           : {f1_score(y_train, xgb_pred_train):.4f}")
print(f"Log loss           : {log_loss(y_train, xgb_pred_train):.4f}")
print(f"AUC-ROC            : {roc_auc_score(y_train, xgb_pred_train):.4f}")
print(f"Mean squared error : {mean_squared_error(y_train, xgb_pred_train):.4f}\n")
print(classification_report(y_train, xgb_pred_train), '\n')

conf_matrix = confusion_matrix(y_train, xgb_pred_train)                   # Hacemos la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Matriz de Confusión del Entrenamiento del Modelo XG Boost")
plt.xlabel("Predicciones")
plt.ylabel("Reales")
plt.show()

# Make predictions on the testing data
xgb_pred_test = xgb_model.predict(X_test)

print("XG Boost (Prueba):\n")
print(f"Accuracy           : {accuracy_score(y_test, xgb_pred_test):.4f}")
print(f"Precision          : {precision_score(y_test, xgb_pred_test):.4f}")
print(f"Recall             : {recall_score(y_test, xgb_pred_test):.4f}")
print(f"F1-score           : {f1_score(y_test, xgb_pred_test):.4f}")
print(f"Log loss           : {log_loss(y_test, xgb_pred_test):.4f}")
print(f"AUC-ROC            : {roc_auc_score(y_test, xgb_pred_test):.4f}")
print(f"Mean squared error : {mean_squared_error(y_test, xgb_pred_test):.4f}\n")
print(classification_report(y_test, xgb_pred_test), '\n')

conf_matrix = confusion_matrix(y_test, xgb_pred_test)                   # Hacemos la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Matriz de Confusión de la Validación del Modelo XG Boost")
plt.xlabel("Predicciones")
plt.ylabel("Reales")
plt.show()

# Graficamos 3 árboles del modelo XG Boost
fig, ax = plt.subplots(figsize=(25, 20))
xgb.plot_tree(xgb_model, num_trees=3, ax=ax)
plt.savefig("xg_boost.png")
plt.show()

"""## **LGBM Classifier**"""

import lightgbm as lgb

# Create an LGBM Classifier model
lgb_model = lgb.LGBMClassifier(n_estimators=100, random_state=42)

# Train the model on the training data
lgb_model.fit(X_train, y_train)

# Make predictions on the training data
lgb_pred_train = lgb_model.predict(X_train)

print("LGBM Classifier (Entrenamiento):\n")
print(f"Accuracy           : {accuracy_score(y_train, lgb_pred_train):.4f}")
print(f"Precision          : {precision_score(y_train, lgb_pred_train):.4f}")
print(f"Recall             : {recall_score(y_train, lgb_pred_train):.4f}")
print(f"F1-score           : {f1_score(y_train, lgb_pred_train):.4f}")
print(f"Log loss           : {log_loss(y_train, lgb_pred_train):.4f}")
print(f"AUC-ROC            : {roc_auc_score(y_train, lgb_pred_train):.4f}")
print(f"Mean squared error : {mean_squared_error(y_train, lgb_pred_train):.4f}\n")
print(classification_report(y_train, lgb_pred_train), '\n')

conf_matrix = confusion_matrix(y_train, lgb_pred_train)                   # Hacemos la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Matriz de Confusión del Entrenamiento del Clasificador LGBM")
plt.xlabel("Predicciones")
plt.ylabel("Reales")
plt.show()

# Make predictions on the testing data
lgb_pred_test = lgb_model.predict(X_test)

print("LGBM Classifier (Prueba):\n")
print(f"Accuracy           : {accuracy_score(y_test, lgb_pred_test):.4f}")
print(f"Precision          : {precision_score(y_test, lgb_pred_test):.4f}")
print(f"Recall             : {recall_score(y_test, lgb_pred_test):.4f}")
print(f"F1-score           : {f1_score(y_test, lgb_pred_test):.4f}")
print(f"Log loss           : {log_loss(y_test, lgb_pred_test):.4f}")
print(f"AUC-ROC            : {roc_auc_score(y_test, lgb_pred_test):.4f}")
print(f"Mean squared error : {mean_squared_error(y_test, lgb_pred_test):.4f}\n")
print(classification_report(y_test, lgb_pred_test), '\n')

conf_matrix = confusion_matrix(y_test, lgb_pred_test)                   # Hacemos la matriz de confusión
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Matriz de Confusión de la Validación del Clasificador LGBM")
plt.xlabel("Predicciones")
plt.ylabel("Reales")
plt.show()

tree1 = random.randint(0, lgb_model.booster_.num_trees() - 1)
tree2 = random.randint(0, lgb_model.booster_.num_trees() - 1)

fig, ax = plt.subplots(nrows=2, figsize=(16,8), sharex=True)
lgb.plot_tree(lgb_model, tree_index=tree1, dpi=300, ax=ax[0])
lgb.plot_tree(lgb_model, tree_index=tree2, dpi=300, ax=ax[1])

"""## **Decision Tree Regressor**"""

#from snapml import DecisionTreeRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error, r2_score

# Create a Decision Tree Regressor model
reg_model = DecisionTreeRegressor()

# Convert train and test data into an array
X_train_arr = np.array(X_train)
y_train_arr = np.array(y_train)

X_test_arr = np.array(X_test)
y_test_arr = np.array(y_test)

# Train the model on the training data
reg_model.fit(X_train_arr, y_train_arr)

# Make predictions on the training data
reg_pred_train = reg_model.predict(X_train_arr)

print("Snap Decision Tree (Entrenamiento):\n")
print(f"MSE      : {mean_squared_error(y_train_arr, reg_pred_train):.4f}")
print(f"MAE      : {mean_absolute_error(y_train_arr, reg_pred_train):.4f}")
print(f"R^2      : {r2_score(y_train_arr, reg_pred_train):.4f}\n")

# Visualization: Plotting the predicted vs actual values
plt.figure(figsize=(6, 4))
plt.scatter(y_train_arr, reg_pred_train, color="blue")
plt.plot([y_train_arr.min(), y_train_arr.max()], [y_train_arr.min(), y_train_arr.max()], 'r--', lw=2)
plt.xlabel('Real')
plt.ylabel('Predicción')
plt.title('Real vs Predicción (Entrenamiento del Snap Decision Tree)')
plt.show()

# Make predictions on the testing data
reg_pred_test = reg_model.predict(X_test_arr)

print("Snap Decision Tree (Entrenamiento):\n")
print(f"MSE      : {mean_squared_error(y_test_arr, reg_pred_test):.4f}")
print(f"MAE      : {mean_absolute_error(y_test_arr, reg_pred_test):.4f}")
print(f"R^2      : {r2_score(y_test_arr, reg_pred_test):.4f}\n")

# Visualization: Plotting the predicted vs actual values
plt.figure(figsize=(6, 4))
plt.scatter(y_test_arr, reg_pred_test, color="blue")
plt.plot([y_test_arr.min(), y_test_arr.max()], [y_test_arr.min(), y_test_arr.max()], 'r--', lw=2)
plt.xlabel('Real')
plt.ylabel('Predicción')
plt.title('Real vs Predicción (Validación del Snap Decision Tree)')
plt.show()

# Export the tree as DOT data
dot_data = StringIO()
export_graphviz(reg_model, out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True, feature_names=X_train.columns)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('regressor_tree.png')
Image(graph.create_png())

