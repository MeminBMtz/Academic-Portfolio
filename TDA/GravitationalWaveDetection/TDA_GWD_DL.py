# -*- coding: utf-8 -*-
"""Copia de gravitational_waves_detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15CD9AuTih_xNrKTLUw2PvTB5Eaod030Z

# Detección de ondas gravitacionales

Christopher Bresten y Jae-Hun Jung proponen incluir características topológicas en un clasificador basado en redes neuronales convolucionales (CNN) para la detección de ondas gravitacionales. Adaptado de su artículo, este notebook muestra una aplicación de ideas del ejemplo de la [Topología de series temporales](https://giotto-ai.github.io/gtda-docs/latest/notebooks/topology_time_series.html).

Si estás viendo una versión estática de este notebook y te gustaría ejecutar su contenido, dirígete a [GitHub](https://github.com/giotto-ai/giotto-tda/blob/master/examples/gravitational_waves_detection.ipynb) y descarga el archivo fuente.

## Referencias útiles

* [Topología de series temporales](https://giotto-ai.github.io/gtda-docs/latest/notebooks/topology_time_series.html), donde se explica en detalle la técnica de *incrustación de Takens* utilizada aquí, ilustrada con ejemplos simples.
* [Detección de ondas gravitacionales usando análisis de datos topológicos y redes neuronales convolucionales: Un enfoque mejorado](https://arxiv.org/abs/1910.08245) por Christopher Bresten y Jae-Hun Jung. Agradecemos a Christopher Bresten por compartir el código y los datos utilizados en el artículo.

## Ver también

- [Topología en pronóstico de series temporales](https://giotto-ai.github.io/gtda-docs/latest/notebooks/time_series_forecasting.html), donde la técnica de incrustación de Takens se aplica a tareas de predicción utilizando ventanas deslizantes.
- [Extracción de características topológicas usando VietorisRipsPersistence y PersistenceEntropy](https://giotto-ai.github.io/gtda-docs/latest/notebooks/vietoris_rips_quickstart.html) para una introducción rápida a la extracción de características topológicas en `giotto-tda`.

**Licencia: AGPLv3**

## Motivación

Los videos a continuación muestran diferentes representaciones de las ondas gravitacionales que buscamos detectar. Nuestro objetivo será identificar la señal de "chirrido" (chirp) producida por la colisión de dos agujeros negros en un entorno con mucho ruido de fondo.
"""

# Uninstall existing packages to ensure a clean installation
!pip uninstall -y numpy scipy giotto-tda tensorflow scikit-learn

# Install all required packages at once to ensure compatibility
!pip install numpy scipy giotto-tda tensorflow scikit-learn

import numpy as np
from pathlib import Path

def make_point_clouds(n_samples_per_shape: int, n_points: int, noise: float):
    """Make point clouds for circles, spheres, and tori with random noise.
    """
    circle_point_clouds = [
        np.asarray(
            [
                [np.sin(t) + noise * (np.random.rand(1)[0] - 0.5), np.cos(t) + noise * (np.random.rand(1)[0] - 0.5), 0]
                for t in range((n_points ** 2))
            ]
        )
        for kk in range(n_samples_per_shape)
    ]
    # label circles with 0
    circle_labels = np.zeros(n_samples_per_shape)

    sphere_point_clouds = [
        np.asarray(
            [
                [
                    np.cos(s) * np.cos(t) + noise * (np.random.rand(1)[0] - 0.5),
                    np.cos(s) * np.sin(t) + noise * (np.random.rand(1)[0] - 0.5),
                    np.sin(s) + noise * (np.random.rand(1)[0] - 0.5),
                ]
                for t in range(n_points)
                for s in range(n_points)
            ]
        )
        for kk in range(n_samples_per_shape)
    ]
    # label spheres with 1
    sphere_labels = np.ones(n_samples_per_shape)

    torus_point_clouds = [
        np.asarray(
            [
                [
                    (2 + np.cos(s)) * np.cos(t) + noise * (np.random.rand(1)[0] - 0.5),
                    (2 + np.cos(s)) * np.sin(t) + noise * (np.random.rand(1)[0] - 0.5),
                    np.sin(s) + noise * (np.random.rand(1)[0] - 0.5),
                ]
                for t in range(n_points)
                for s in range(n_points)
            ]
        )
        for kk in range(n_samples_per_shape)
    ]
    # label tori with 2
    torus_labels = 2 * np.ones(n_samples_per_shape)

    point_clouds = np.concatenate((circle_point_clouds, sphere_point_clouds, torus_point_clouds))
    labels = np.concatenate((circle_labels, sphere_labels, torus_labels))

    return point_clouds, labels


def make_gravitational_waves(
    path_to_data: Path,
    n_signals: int = 30,
    downsample_factor: int = 2,
    r_min: float = 0.075,
    r_max: float = 0.65,
    n_snr_values: int = 10,
        ):
    def padrand(V, n, kr):
        cut = np.random.randint(n)
        rand1 = np.random.randn(cut)
        rand2 = np.random.randn(n - cut)
        out = np.concatenate((rand1 * kr, V, rand2 * kr))
        return out

    Rcoef = np.linspace(r_min, r_max, n_snr_values)
    Npad = 500  # number of padding points on either side of the vector
    gw = np.load(path_to_data / "gravitational_wave_signals.npy")
    Norig = len(gw["data"][0])
    Ndat = len(gw["signal_present"])
    N = int(Norig / downsample_factor)

    ncoeff = []
    Rcoeflist = []

    for j in range(n_signals):
        ncoeff.append(10 ** (-19) * (1 / Rcoef[j % n_snr_values]))
        Rcoeflist.append(Rcoef[j % n_snr_values])

    noisy_signals = []
    gw_signals = []
    k = 0
    labels = np.zeros(n_signals)

    for j in range(n_signals):
        signal = gw["data"][j % Ndat][range(0, Norig, downsample_factor)]
        sigp = int((np.random.randn() < 0))
        noise = ncoeff[j] * np.random.randn(N)
        labels[j] = sigp
        if sigp == 1:
            rawsig = padrand(signal + noise, Npad, ncoeff[j])
            if k == 0:
                k = 1
        else:
            rawsig = padrand(noise, Npad, ncoeff[j])
        noisy_signals.append(rawsig.copy())
        gw_signals.append(signal)

    return noisy_signals, gw_signals, labels

from IPython.display import YouTubeVideo

YouTubeVideo("Y3eR49ogsF0", width=600, height=400)

YouTubeVideo("QyDcTbR-kEA", width=600, height=400)

"""## Generar los datos

En el artículo, los autores crean un conjunto de entrenamiento sintético de la siguiente manera:

* Generan señales de ondas gravitacionales que corresponden a fusiones de agujeros negros binarios sin rotación.
* Generan una serie temporal ruidosa e insertan una señal de onda gravitacional con una probabilidad de 0.5 en un momento aleatorio.

El resultado es un conjunto de series temporales de la forma

$$ s = g + \epsilon \frac{1}{R}\xi $$

donde $g$ es una señal de onda gravitacional del conjunto de referencia, $\xi$ es ruido gaussiano, $\epsilon=10^{-19}$ escala la amplitud del ruido respecto a la señal, y $R \in (0.075, 0.65)$ es un parámetro que controla la relación señal-ruido (SNR).

## Relación señal-ruido constante

Como calentamiento, generemos algunas señales ruidosas con una relación señal-ruido (SNR) constante de 17.98. Como se muestra en la Tabla 1 del artículo, esto corresponde a un valor de $R$ de 0.65. Al elegir el extremo superior del intervalo, nos colocamos en un escenario favorable y, por lo tanto, podemos tener una idea del mejor rendimiento posible para nuestro clasificador de series temporales.

Elegimos un número pequeño de muestras para que los cálculos se realicen rápidamente, pero en la práctica esto se escalaría entre 1 y 2 órdenes de magnitud, como se hizo en el artículo original.
"""

from pathlib import Path

R = 0.65
n_signals = 100
DATA = Path(".")

noisy_signals, gw_signals, labels = make_gravitational_waves(
    path_to_data=DATA, n_signals=n_signals, r_min=R, r_max=R, n_snr_values=1
)

print(f"Number of noisy signals: {len(noisy_signals)}")
print(f"Number of timesteps per series: {len(noisy_signals[0])}")

"""A continuación, visualicemos los dos tipos diferentes de series temporales que deseamos clasificar: una que consiste únicamente en ruido, y otra que está compuesta por ruido más una señal de onda gravitacional incrustada:

"""

import numpy as np
from plotly.subplots import make_subplots
import plotly.graph_objects as go

# get the index corresponding to the first pure noise time series
background_idx = np.argmin(labels)
# get the index corresponding to the first noise + gravitational wave time series
signal_idx = np.argmax(labels)

ts_noise = noisy_signals[background_idx]
ts_background = noisy_signals[signal_idx]
ts_signal = gw_signals[signal_idx]

fig = make_subplots(rows=1, cols=2)

fig.add_trace(
    go.Scatter(x=list(range(len(ts_noise))), y=ts_noise, mode="lines", name="noise"),
    row=1,
    col=1,
)

fig.add_trace(
    go.Scatter(
        x=list(range(len(ts_background))),
        y=ts_background,
        mode="lines",
        name="background",
    ),
    row=1,
    col=2,
)

fig.add_trace(
    go.Scatter(x=list(range(len(ts_signal))), y=ts_signal, mode="lines", name="signal"),
    row=1,
    col=2,
)
fig.show()

"""Hacemos dos observaciones:
1. Es difícil distinguir la señal a simple vista,
2. La señal presenta cierta regularidad o periodicidad.

Ambas observaciones nos llevan a examinar la _**incrustación de Takens**_ de la señal $s(t)$, con el fin de capturar su estructura recurrente. De hecho, si $f$ se toma de un sistema dinámico con una estructura recurrente no trivial, entonces, con los parámetros adecuados, la imagen bajo la incrustación tendrá una topología no trivial.

Más formalmente, extraemos una secuencia de vectores en $\mathbb{R}^{d}$ de la forma

$$
TD_{d,\tau} s : \mathbb{R} \to \mathbb{R}^{d}\,, \qquad t \to \begin{bmatrix}
           s(t) \\
           s(t + \tau) \\
           s(t + 2\tau) \\
           \vdots \\
           s(t + (d-1)\tau)
         \end{bmatrix},
$$

donde $d$ es la dimensión de la incrustación y $\tau$ es el retardo de tiempo. La cantidad $(d-1)\tau$ se conoce como el "tamaño de ventana" y la diferencia entre $t_{i+1}$ y $t_i$ se denomina paso (*stride*).

Veamos cómo se ve la incrustación por retardo temporal de una señal pura de onda gravitacional:

"""

from gtda.time_series import SingleTakensEmbedding
embedding_dimension = 30
embedding_time_delay = 30
stride = 5

embedder = SingleTakensEmbedding(
    parameters_type="search", n_jobs=6, time_delay=embedding_time_delay, dimension=embedding_dimension, stride=stride
)

y_gw_embedded = embedder.fit_transform(gw_signals[0])

"""Podemos usar PCA para proyectar nuestro espacio de alta dimensión a 3 dimensiones para su visualización:

"""

from sklearn.decomposition import PCA
from gtda.plotting import plot_point_cloud

pca = PCA(n_components=3)
y_gw_embedded_pca = pca.fit_transform(y_gw_embedded)

plot_point_cloud(y_gw_embedded_pca)

"""¡A partir de la gráfica podemos ver que la señal periódica decreciente generada por la fusión de agujeros negros aparece como una _espiral_ en el espacio de incrustación por retardo temporal!

Para contrastar, comparemos esto con una de las series temporales de ruido puro en nuestra muestra:

"""

embedding_dimension = 30
embedding_time_delay = 30
stride = 5

embedder = SingleTakensEmbedding(
    parameters_type="search", n_jobs=6, time_delay=embedding_time_delay, dimension=embedding_dimension, stride=stride
)

y_noise_embedded = embedder.fit_transform(noisy_signals[background_idx])

pca = PCA(n_components=3)
y_noise_embedded_pca = pca.fit_transform(y_noise_embedded)

plot_point_cloud(y_noise_embedded_pca)

"""Evidentemente, el ruido puro se asemeja a una esfera de alta dimensión en el espacio de incrustación por retardo temporal. Veamos si podemos utilizar homología persistente para distinguir qué series temporales contienen una señal de onda gravitacional y cuáles no. Para ello, adaptaremos la estrategia del artículo original:

1. Generar incrustaciones por retardo temporal de 200 dimensiones para cada serie temporal  
2. Utilizar PCA para reducir las incrustaciones a 3 dimensiones  
3. Usar la construcción de Vietoris-Rips para calcular los diagramas de persistencia de los generadores de $H_0$ y $H_1$  
4. Extraer vectores de características utilizando la entropía de persistencia  
5. Entrenar un clasificador binario usando las características topológicas

### Definir el pipeline de generación de características topológicas

Podemos realizar los pasos 1 y 2 utilizando las siguientes herramientas de ``giotto-tda``:

- El transformador ``TakensEmbedding`` – en lugar de ``SingleTakensEmbedding`` – que transformará cada serie temporal en ``noisy_signals`` por separado y devolverá una colección de nubes de puntos;
- ``CollectionTransformer``, que es un "meta-estimador" conveniente para aplicar el mismo PCA a cada nube de puntos resultante del paso 1.

Usando la clase ``Pipeline`` de ``giotto-tda``, podemos encadenar todas las operaciones hasta e incluyendo el paso 4 de la siguiente manera:
"""

from gtda.diagrams import PersistenceEntropy, Scaler
from gtda.homology import VietorisRipsPersistence
from gtda.metaestimators import CollectionTransformer
from gtda.pipeline import Pipeline
from gtda.time_series import TakensEmbedding

embedding_dimension = 200
embedding_time_delay = 10
stride = 10

embedder = TakensEmbedding(time_delay=embedding_time_delay,
                           dimension=embedding_dimension,
                           stride=stride)

batch_pca = CollectionTransformer(PCA(n_components=3), n_jobs=-1)

persistence = VietorisRipsPersistence(homology_dimensions=[0, 1, 2], n_jobs=-1)

scaling = Scaler()

entropy = PersistenceEntropy(normalize=True, nan_fill_value=-10)


steps = [("embedder", embedder),
         ("pca", batch_pca),
         ("persistence", persistence),
         ("scaling", scaling),
         ("entropy", entropy)]
topological_transfomer = Pipeline(steps)

features = topological_transfomer.fit_transform(noisy_signals)

import pandas as pd

noisy_df = pd.DataFrame(noisy_signals)
features_df = pd.DataFrame(features)
features_df.columns = ['features 0', 'features 1', 'features 2']

noisy_df_normalized = noisy_df.apply(lambda x: (x - x.mean()) / x.std(), axis=1)

features_df_normalized = features_df.apply(lambda x: (x - x.mean()) / x.std(), axis=0)

df = pd.concat([noisy_df_normalized,
                features_df_normalized], axis=1)

# Convert all column names to strings
df.columns = df.columns.astype(str)
df

"""### Entrenar y evaluar un modelo

Para el paso final, entrenemos un clasificador sencillo usando nuestras características topológicas. Como es habitual, creamos conjuntos de entrenamiento y validación.

# **Clasificadores**

**Pre-procesamiento y métricas de evaluación**

Se dividió el conjunto de datos en conjuntos de entrenamiento y validación usando `train_test_split`, reservando el 30 % de los datos para validación. Luego, se definió una función llamada `print_scores` que evalúa un modelo entrenado calculando su precisión (Accuracy) y el área bajo la curva ROC (ROC AUC), tanto en el conjunto de entrenamiento como en el de validación. Estos indicadores permiten medir qué tan bien se desempeña el modelo al clasificar correctamente las series temporales con o sin señales de ondas gravitacionales.
"""

from sklearn.model_selection import train_test_split

X_train, X_valid, y_train, y_valid = train_test_split(
    df, labels, test_size=0.3, random_state=42
)

X_train

y_train

X_valid

y_valid

"""
y luego ajustamos y evaluamos nuestro modelo:
"""

import matplotlib.pyplot as plt

from sklearn.metrics import precision_score

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import accuracy_score, roc_auc_score

def print_scores(fitted_model):
    res = {
        "Accuracy on train:": accuracy_score(fitted_model.predict(X_train), y_train),
        "ROC AUC on train:": roc_auc_score(
            y_train, fitted_model.predict_proba(X_train)[:, 1]
        ),
        "Accuracy on valid:": accuracy_score(fitted_model.predict(X_valid), y_valid),
        "ROC AUC on valid:": roc_auc_score(
            y_valid, fitted_model.predict_proba(X_valid)[:, 1]
        ),
    }

    for k, v in res.items():
        print(k, round(v, 3))

"""# **Regresión Logística**

Se entrenó un modelo de regresión logística (`LogisticRegression`) utilizando las características topológicas extraídas previamente. Luego, se evaluó el modelo tanto en el conjunto de entrenamiento como en el de validación usando métricas como `accuracy` (precisión global) y `ROC AUC` (área bajo la curva ROC), además de generar reportes de clasificación y matrices de confusión visualizadas con `seaborn`.
"""

from sklearn.linear_model import LogisticRegression

LR = LogisticRegression()
LR.fit(X_train, y_train)
print_scores(LR)

print(classification_report(y_train, (LR.predict(X_train)).astype(int)))

import seaborn as sns
cm = confusion_matrix(y_train, (LR.predict(X_train)).astype(int))
sns.heatmap(cm, annot = True)
plt.show()

print(classification_report(y_valid, (LR.predict(X_valid)).astype(int)))

cm = confusion_matrix(y_valid, (LR.predict(X_valid)).astype(int))
sns.heatmap(cm, annot = True)
plt.show()

"""En los resultados, el modelo alcanzó una precisión perfecta en el conjunto de entrenamiento (100 %), lo que sugiere sobreajuste. Esto se refleja también en la matriz de confusión, donde todos los ejemplos se clasificaron correctamente. Sin embargo, en el conjunto de validación, la precisión cayó a 66.7 % y el ROC AUC fue de 0.57, lo cual indica que el modelo no generaliza bien y tiene dificultades para distinguir entre ruido y señales reales en datos nuevos. La matriz de confusión de validación muestra varios falsos negativos (ondas mal clasificadas como ruido), lo que evidencia una limitación importante que podría mejorarse con regularización, más datos o un modelo más complejo.

# ***Random Forest Classifier***

Se entrenó un modelo `RandomForestClassifier` usando el conjunto de entrenamiento `X_train` y `y_train`, y se evaluó su rendimiento con la función `print_scores`, que muestra métricas como precisión (`accuracy`) y área bajo la curva ROC (`ROC AUC`) para entrenamiento y validación. Posteriormente, se imprimió el reporte de clasificación (`classification_report`) para visualizar precisión, recall y F1-score por clase, seguido por las matrices de confusión de entrenamiento y validación utilizando `seaborn.heatmap` para facilitar la interpretación visual de los aciertos y errores del modelo.
"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(X_train, y_train)
print_scores(rf)

print(classification_report(y_train, (rf.predict(X_train)).astype(int)))

cm = confusion_matrix(y_train, (rf.predict(X_train)).astype(int))
sns.heatmap(cm, annot = True)
plt.show()

print(classification_report(y_valid, (rf.predict(X_valid)).astype(int)))

cm = confusion_matrix(y_valid, (rf.predict(X_valid)).astype(int))
sns.heatmap(cm, annot = True)
plt.show()

"""El modelo de Random Forest mostró un rendimiento perfecto en el conjunto de entrenamiento, con un 100 % de precisión y métricas perfectas en el reporte de clasificación, lo que indica un fuerte sobreajuste. En cambio, su rendimiento en el conjunto de validación fue bajo: una precisión de solo 43.3 % y un ROC AUC de 0.394. La matriz de confusión de validación revela una dificultad considerable para identificar correctamente las señales de onda gravitacional (clase 1), con solo 2 aciertos y 11 falsos negativos. Estos resultados reflejan que, aunque el modelo puede memorizar bien los datos de entrenamiento, falla al generalizar a nuevos datos, sugiriendo que necesita ajustes como reducción de complejidad, más datos o técnicas de regularización.

# ***Convolutional Neural Networks***

# **Red del *Paper*: *MaxPooling***

Se construyó una red neuronal convolucional secuencial en Keras para clasificar señales de ondas gravitacionales. El modelo está compuesto por cuatro bloques de capas `Conv1D` seguidos de capas `MaxPooling1D`, que extraen y reducen las características relevantes de las series temporales. Luego, se aplanan las salidas con `Flatten()` y se pasan por varias capas densas (`Dense`) para realizar la clasificación binaria final mediante una activación `sigmoid`. El modelo fue compilado con el optimizador `Adam` y función de pérdida `binary_crossentropy`, y se entrenó durante 10 épocas con un `validation_split` de 0.2. Finalmente, se graficó la curva de pérdida y se evaluó el modelo sobre el conjunto de validación.
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Input, Reshape, ReLU
from tensorflow.keras.optimizers import Adam

cnn1 = Sequential()

cnn1.add(Input(shape=(X_train.shape[1], 1)))

# Bloque 1
cnn1.add(Conv1D(32, kernel_size=16, strides=1, activation='relu'))
cnn1.add(MaxPooling1D(pool_size=4, strides=4))

# Bloque 2
cnn1.add(Conv1D(64, kernel_size=16, strides=1, activation='relu'))
cnn1.add(MaxPooling1D(pool_size=4, strides=4))

# Bloque 3
cnn1.add(Conv1D(128, kernel_size=16, strides=1, activation='relu'))
cnn1.add(MaxPooling1D(pool_size=4, strides=4))

# Bloque 4
cnn1.add(Conv1D(256, kernel_size=32, strides=1, activation='relu'))
cnn1.add(MaxPooling1D(pool_size=4, strides=4))

# Salida
cnn1.add(Flatten())
cnn1.add(Dense(128, activation='linear'))
cnn1.add(Dense(128, activation='relu'))
cnn1.add(Dense(64, activation='linear'))
cnn1.add(Dense(64, activation='relu'))
cnn1.add(Dense(1, activation='sigmoid'))

cnn1.summary()

# Compilar
optimizer = Adam(learning_rate=0.001)
cnn1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenar
history = cnn1.fit(X_train, y_train, validation_split=0.2,
                  epochs=10,  # como en el paper
                  batch_size=16)

# Visualizar curva de pérdida
plt.plot(history.history['loss'], label='Pérdida de entrenamiento')
plt.plot(history.history['val_loss'], label='Pérdida de validación')
plt.title('Curva de pérdida')
plt.xlabel('Época')
plt.ylabel('Pérdida (Binary Crossentropy)')
plt.legend()
plt.grid(True)
plt.show()

loss, accuracy = cnn1.evaluate(X_valid, y_valid)
print('Exactitud del modelo:', accuracy)

# Usamos el modelo para predecir
y_pred = (cnn1.predict(X_valid)).astype(int)

# Resumen de los primeros 25 casos
for i in range(25): print('%d (Esperado: %d)' % (y_pred[i], y_valid[i]))

cm = confusion_matrix(y_valid, y_pred)
sns.heatmap(cm, annot = True)
plt.show()

cm = confusion_matrix(y_train, (cnn1.predict(X_train)).astype(int))
sns.heatmap(cm, annot = True)
plt.show()

print(classification_report(y_train, (cnn1.predict(X_train)).astype(int)))

print(classification_report(y_valid, (cnn1.predict(X_valid)).astype(int)))

"""Durante el entrenamiento, la red mostró una mejora rápida en precisión y reducción de pérdida en las primeras épocas, alcanzando una exactitud perfecta tanto en el entrenamiento como en la validación en algunas iteraciones. Sin embargo, la matriz de confusión y los reportes de clasificación revelan que, aunque el modelo predijo correctamente muchos casos, también incurrió en falsos negativos al identificar ondas gravitacionales (clase 1). La precisión general en validación fue del 80 %, con una F1-score de 0.70 para la clase 1, lo que indica un buen desempeño general con espacio para mejorar en la sensibilidad hacia señales más sutiles. La gráfica de pérdida sugiere cierto sobreajuste en épocas tardías, aunque no de forma severa.

# **Red 2: *AvgPooling***

Se construyó una red neuronal convolucional de tipo `Sequential` usando `Conv1D` y `AveragePooling1D` para el procesamiento de señales unidimensionales. La arquitectura incluye cuatro bloques convolucionales con capas `Conv1D` activadas por `ReLU`, seguidas de `AveragePooling1D` para reducir la dimensionalidad. Luego, la salida se aplana y pasa por una serie de capas densas (`Dense`), culminando en una capa con activación `sigmoid` para realizar la clasificación binaria. El modelo se entrenó durante 10 épocas con `binary_crossentropy` como función de pérdida y se evaluó tanto en entrenamiento como en validación. También se generaron gráficas de pérdida y matrices de confusión.
"""

from tensorflow.keras.layers import AveragePooling1D

model2 = Sequential()

model2.add(Input(shape=(X_train.shape[1], 1)))  # Ajusta la dimensión según tu entrada

# Bloque 1
model2.add(Conv1D(32, kernel_size=16, strides=1, activation='relu'))
model2.add(AveragePooling1D(pool_size=4, strides=4))

# Bloque 2
model2.add(Conv1D(64, kernel_size=16, strides=1, activation='relu'))
model2.add(AveragePooling1D(pool_size=4, strides=4))

# Bloque 3
model2.add(Conv1D(128, kernel_size=16, strides=1, activation='relu'))
model2.add(AveragePooling1D(pool_size=4, strides=4))

# Bloque 4
model2.add(Conv1D(256, kernel_size=32, strides=1, activation='relu'))
model2.add(AveragePooling1D(pool_size=4, strides=4))

# Salida
model2.add(Flatten())
model2.add(Dense(128, activation='linear'))
model2.add(Dense(128, activation='relu'))
model2.add(Dense(64, activation='linear'))
model2.add(Dense(64, activation='relu'))
model2.add(Dense(1, activation='sigmoid'))

model2.summary()

# Compilar
optimizer = Adam(learning_rate=0.001)
model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenar
history = model2.fit(X_train, y_train, validation_split=0.2,
                    epochs=10,  # como en el paper
                    batch_size=16)

# Visualizar curva de pérdida
plt.plot(history.history['loss'], label='Pérdida de entrenamiento')
plt.plot(history.history['val_loss'], label='Pérdida de validación')
plt.title('Curva de pérdida')
plt.xlabel('Época')
plt.ylabel('Pérdida (Binary Crossentropy)')
plt.legend()
plt.grid(True)
plt.show()

loss, accuracy = model2.evaluate(X_valid, y_valid)
print('Exactitud del modelo:', accuracy)

# Usamos el modelo para predecir
y_pred = (model2.predict(X_valid)).astype(int)

# Resumen de los primeros 25 casos
for i in range(25): print('%d (Esperado: %d)' % (y_pred[i], y_valid[i]))

cm = confusion_matrix(y_valid, y_pred)
sns.heatmap(cm, annot = True)
plt.show()

cm = confusion_matrix(y_train, (model2.predict(X_train)).astype(int))
sns.heatmap(cm, annot = True)
plt.show()

print(classification_report(y_train, (model2.predict(X_train)).astype(int)))

print(classification_report(y_valid, (model2.predict(X_valid)).astype(int)))

"""El modelo con `AveragePooling` mostró un desempeño sólido, alcanzando una precisión del 93.3 % en el conjunto de validación con una pérdida de 0.14. Durante el entrenamiento, tanto la pérdida como la precisión mejoraron progresivamente, y la curva de pérdida indica una buena convergencia sin señales evidentes de sobreajuste. Sin embargo, el modelo mostró cierta dificultad al clasificar correctamente todas las instancias de la clase 1 (ondas gravitacionales), cometiendo 5 falsos negativos. A pesar de ello, el modelo logró una F1-score de 0.76 para esa clase y un desempeño general equilibrado, ligeramente inferior al modelo con `MaxPooling`, pero con un buen nivel de generalización.

# **Conclusión General**

Este proyecto implementa un enfoque para la detección de ondas gravitacionales inspirándose en el trabajo de Bresten y Jung, combinando técnicas de análisis topológico con aprendizaje automático y redes neuronales profundas. Se parte de un conjunto de señales sintéticas que emulan colisiones de agujeros negros inmersas en ruido gaussiano, con diferentes relaciones señal-ruido (SNR).

Primero, se aplicó la incrustación de Takens para representar las señales en un espacio de mayor dimensión donde emergen patrones topológicos. Estas representaciones fueron reducidas a tres dimensiones mediante PCA y convertidas en características numéricas usando diagramas de persistencia (`VietorisRipsPersistence`) y entropía de persistencia.

Con estas características, se entrenaron múltiples clasificadores:

- **Modelos clásicos** como Regresión Logística y Random Forest demostraron sobreajuste severo o bajo rendimiento en validación.
- **Redes neuronales convolucionales (CNN)** superaron ampliamente a los modelos clásicos. La arquitectura basada en **MaxPooling** alcanzó una precisión del 80 %, mientras que la versión con **AveragePooling** llegó al 83 %, ambas con buen balance entre precisión y sensibilidad para detectar señales reales.
- La combinación de CNN + reducción de dimensionalidad + extracción topológica probó ser efectiva, como se mostró tanto en las curvas de pérdida como en las matrices de confusión.

En resumen, el uso de topología algebraica para enriquecer los datos de entrada, seguido de una CNN especializada, constituye una estrategia poderosa para detectar patrones sutiles en series temporales ruidosas, validando las hipótesis planteadas en el artículo original.
"""